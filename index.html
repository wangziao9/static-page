<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>The List is Incomplete!</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>(Not So) Recent advances in Large Language Models</h1>
    <p>September 2024</p>
    <a href="https://github.com/wangziao9/static-page">source code</a>
    <h2>Retrival Augmented Generation</h2>
    <ul>
        <li>Leverage domain specific knowledge</li>
        <li>Awareness of news via real time updates</li>
        <li>Generate citations or anchors to data, improve verifiability and trust</li>
    </ul>
    <h2>FlashAttention</h2>
    <img src="flashattention.png" alt="Diagram of Flash Attention">
    <p>Image courtesy of <a href="https://arxiv.org/abs/2205.14135"><i>FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</i></a></p>
    <h2>Tree of Thoughts</h2>
    <table>
        <tr>
            <th>Mode</th>
            <th>1</th>
            <th>2</th>
        </tr>
        <tr class="analogy">
            <td>Human</td>
            <td>System 1</td>
            <td>System 2</td>
        </tr>
        <tr>
            <td>Characteristics</td>
            <td>Fast, automatic, unconscious</td>
            <td>Slow, deliberate, conscious</td>
        </tr>
        <tr class="analogy">
            <td>Machine</td>
            <td>Inference</td>
            <td>Search</td>
        </tr>
        <tr>
            <td>AlphaGo</td>
            <td>Policy network and value network</td>
            <td>Tree search through a combinatorial problem space</td>
        </tr>
        <tr>
            <td>LLM</td>
            <td>Per-token generation</td>
            <td>?</td>
        </tr>
    </table>
</body>
</html>